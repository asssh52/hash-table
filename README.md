
# Оптимизация хэш-таблицы на односвязном списке при помощи intrinsic-функций и знаний ассемблера.
    
В этой работе изучались способы ускорить (используя аппаратные оптимизации) время работы некоторого теста для `хэш-таблицы`. Тест заключался в измерении времени работы добавления слов из большого текста (в моём случае перевод романа "Война и мир" Л.Н. Толстого), и дальнейшем поиске слов из тестового файла в хэш-таблице. 

В рамках задачи, было предложено подобрать количество `bucket'ов` для среднего `load factor'а` в ~15, для увеличения важности аппаратных оптимизаций.  
Пусть в таком случае первым способом алгоритмической оптимизации и было бы увеличение числа bucket'ов (для уменьшения фактора загрузки до ~1), мы не будем его рассматривать в рамках учебной задачи.

## Цели:

- Написать базовую версию программы.
- Ознакомиться с профилировщиками. `(perf/valgrind)`
- Найти узкие места для оптимизации с помощью `профилировщиков`.
- Оптимизировать эти места используя: `intrinsic-функции`, `внешние функции на ассемблере`, `inline-assembler компилятора`.
- Повторить пункты `3-4`, пока относительное ускорение не достигнет 2-5%.

## Характеристики процессора.

          description: CPU
          product: QEMU Virtual CPU version 4.2.0
          vendor: Intel Corp.
          physical id: 400
          bus info: cpu@0
          version: 6.58.9
          slot: CPU 0
          size: 2GHz
          capacity: 2GHz
          width: 64 bits
          capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx pdpe1gb rdtscp x86-64 constant_tsc rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm cpuid_fault invpcid_single pti ssbd ibrs ibpb fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap xsaveopt arat md_clear
          configuration: cores=1 enabledcores=1 microcode=1 threads=1 
## Методика и обработка измерений.
Измерения проводятся в пределах от 5 до 15 раз и после этого находится среднеквадратичное отклонение для каждой версии программы:

$$\sigma_{avg} = \sqrt{\frac{1}{n(n-1)} \sum_{i=1}^n (x_i - x_{avg})^2}$$

далее рассчитывается относительная погрешность:

$$\epsilon = \frac{\sigma_{avg}}{x_{avg}}$$

Сами [измерения](https://docs.google.com/spreadsheets/d/1icauuBQ5HtbhLJr3FG2q25h-3lAFZVmTFjN7yMbTIuk/edit?usp=sharing).
## Основная часть.
- Написание базовой версии программы.


В качестве способа измерения производительности был выбран отсчёт тактов процессора с помощью функции `__rdtsc`, а также `perf stat` для оценки.

Были реализованы несколько основных функций для работы с таблицей, такие как: добавление нового элемета, поиск элемента и тестирующая функция(а также конструктор/деструктор/дамп/верификатор). В качестве хэш-функции была выбрана `crc32`, в силу несложной реализации и равномерного распределения.

Вот реализация `crc32`:

```c++
...
#define MAX_NAME 32
const int POLYNOM = 0xEDB88320;
...

uint calcHash(char* name, uint prevHash){

    int length = MAX_NAME;
    uint crc = prevHash;
    for(int i = 0; i < MAX_NAME; i++){
        crc = crc ^ (name[i]);
        for (unsigned int j = 0; j < 8; j++){
            if (crc & 1){ crc = (crc >> 1) ^ POLYNOM;}
            else{ crc = crc >> 1;}
        }
    }

    return ~crc;
}
```

Да, это далеко не самый быстрый вариант, два вложенных цикла - 256 итераций внутреннего цикла говорят сами за себя (да это ещё и для каждого слова..). Однако, процитирую [Дональда Кнута](https://ru.wikiquote.org/wiki/Дональд_Кнут): `"Преждевременная оптимизация - корень большинства проблем в программировании"`. Поэтому отложим размышления на эту тему до этапа профилирования.

Проведём измерения производительности базовой версии скомпилированной с/без флага -O3([исходники](https://docs.google.com/spreadsheets/d/1icauuBQ5HtbhLJr3FG2q25h-3lAFZVmTFjN7yMbTIuk/edit?usp=sharing)):

| Версия       | v1       |  v1_O3     |
|:-:           |:-------: |:----------:|
| Такты * 10^9 |  46,1    |    8,4     |
| Ускорение    |  1,00    |    5,48    |
| Погрешность  |  0,01    |    0,01    |

В целом, результаты ожидаемые, оптимизатор как всегда творит чудеса.

### Настало время первого профилирования.

Воспользуемся, например, профилировщиком `valgrind` с утилитой `callgrind` и графической оболочкой для просмотра результатов `kachegrind`, результаты отсортированны по показателю `self`:

# Картинка v1
<img src="https://github.com/user-attachments/assets/73bd46f0-188c-4178-ae22-471c93eb95cb" width="800">


# Картинка v1_O3
<img src="https://github.com/user-attachments/assets/97042b39-3bc6-4ede-8f01-e9601f7d8e75" width="800">
<img src="https://github.com/user-attachments/assets/5c8230df-48b0-4f39-9057-7ca626e92ea8" width="800">

Можно заметить, что процент времени занимаемый функциями `hashTableAdd` и `hashTableFind` сильно возрос, а `countHash` пропала вовсе, это происходит из-за инлайнинга функции расчёта хэша в них. Получается, самая используемая функция это `countHash` (не особо и удивительно). Перепишем её используя `intrinsic`-функции:

```c++
unsigned long long calcHash(char* name){

    unsigned long long crc = 0xFFFFFFFFFFFFFFFF; // same as previousCrc32 ^ 0xFFFFFFFF

    for (int i = 0; i < MAX_NAME / 8; i++){
        unsigned long long next = *((unsigned long long*)name + i);
        crc = _mm_crc32_u64(crc, next);
    }

    return crc;
}
```

В теории, это должно дать гигантский прирорст к производительности, мы заменили гигантский цикл - на всего лишь 4 инструкции процессора. Итак, отн. ускорение - относительно левой версии в таблице(v1_O3 отн. v1, v2_O3 отн. v1_O3):

| Версия            | v1       |  v1_O3     | v2_O3         |
|:-:                |:-------: |:----------:|:----------:   |
| Такты * 10^9      |  46,1    |    8,4     |2,6            |
| Ускорение         |  1,00    |    5,48    |17,7           |
| Отн. ускорение    |  1,00    |    5,48    |3,23           |
| Погрешность       |  0,01    |    0,01    |0,06           |

Результаты ожидаемые, найдём следующее узкое место в программе.

# Картинка v2_O3
<img src="https://github.com/user-attachments/assets/06bbd8cc-56a7-45e5-ba3d-767f1b6e738b" width="800">
<img src="https://github.com/user-attachments/assets/8fa4bc00-f91d-4e43-8b12-40f1d3ca162e" width="800">

Видим, что время работы программы ускорилось в 3 раза, а доля `strncmp` возросла в ~7 раз - выбор был сделан верный, тут же отчётливо видно следующее место для оптимизации. Так как нам не нужен полный функционал `strncmp`, а нам нужно знать равны ли две строки между собой, покопаемся в [intel intrinsics guide](https://www.laruence.com/sse/#cats=Compare&techs=AVX,AVX2&expand=900) и найдём нужную нам SIMD-инструкцию.

Наша функция сравнения - `meowcmp`. Первые две инструкции перемещают слова по 32 байта в `ymm` регистры, третья - записывает результат побайтового сравнения в `ymm0`, четвёртая собирает битики из каждого байта и делает из них 32-разрядное число, то есть, если два слова равны между собой функция выдаст `11...11` - в двоичной системе, дальше мы можем инвертировать их, и получим `0`, прямо как в библиотечном `strncmp`.  

```asm
section .text

global meowcmp

;RDI, RSI - string ptrs

meowcmp:

    vmovups ymm0, yword [rdi]
    vmovups ymm1, yword [rsi]

    vpcmpeqb ymm0, ymm0, ymm1
    vpmovmskb eax, ymm0

    ret
```

Посмотрим на результаты такого урезания `strncmp` под нашу задачу.

# Картинка v3_O3
<img src="https://github.com/user-attachments/assets/f6a9e854-074a-4bfe-b25c-bbd0a422f459" width="800">

Для проверки воспользуемся `perf`'ом.

# Картинка v3_O3
<img src="https://github.com/user-attachments/assets/1e991c28-20f1-4f27-9046-34bbdec3b4d0" width="800">

# Картинка v3_O3
<img src="https://github.com/user-attachments/assets/1f12bf7b-d799-41a6-af3b-e524f10765bb" width="800">


В основном результаты профилировщиков коррелируют между собой, однако при записи этих данных у `perf`'а наблюдался некоторый разброс в показаниях. Это связано с механизмом работы самого профилировщика. А вот результаты измерений времени:

| Версия            | v1       |  v1_O3     | v2_O3         | v3_O3         |
|:-:                |:-------: |:----------:|:----------:   |:----------:   |
| Такты * 10^9      |  46,1    |    8,42     |2,63            | 1,94          |  
| Ускорение         |  1,00    |    5,48    |17,7           | 23,8          |  
| Отн. ускорение    |  1,00    |    5,48    |3,23           | 1,34          |
| Погрешность       |  0,01    |    0,01    |0,06           | 0,05          |

Нам удалось ускорить функцию сравнения примерно на `40%`, что весьма существенно повлияло на время работы программы, так как доля `strncmp` была наивысшей.

Из отчёта `valgrind`'а и `perf`'а можно сделать вывод, что первые 3 (в случае perf'a 2) функции уже были нами оптимизированны, следующая на очереди `memcpy` и `strlen`, которые вызываются из мест, приведённых ниже. Однако, стоит помнить о том, что их суммарный вес не более `4%` от программы, если результат получится незначительным - следует вернуться к предыдущей версии, потому как такие оптимизации ухудшают читаемость кода и делают его непереносимым на другие архитектуры.

```c++

int hashTblAdd(hashTbl_t* hashtbl, char* name){
    if (hashTblVtor(hashtbl)) return ERR;

    char smallBuff[MAX_NAME] = {};
    int len = strlen(name);
    memcpy(smallBuff, name, len);

    unsigned long long hash = countHash(smallBuff);
    bucketAdd(hashtbl, hashtbl->buckets + hash % NUM_BCKT, smallBuff);

    return OK;
}
```

```c++

int bucketAdd(hashTbl_t* hashtbl, bucket_t** list, char* name){
    if (listFind(hashtbl, *list, name)) return OK;

    bucket_t* old_list = *list;

    *list = (bucket_t*)calloc(1, sizeof(bucket_t));

    memcpy((*list)->name, name, MAX_NAME);

    (*list)->next = old_list;

    return OK;
}
```

Первоначально, была проведена попытка ускорить второй вызов `memcpy`:

```c++
  int bucketAdd(hashTbl_t* hashtbl, bucket_t** list, char* name){
    if (listFind(hashtbl, *list, name)) return OK;

    bucket_t* old_list = *list;

    *list = (bucket_t*)calloc(1, sizeof(bucket_t));

    asm(".intel_syntax noprefix\n\t"
        "vmovups ymm0, ymmword ptr [rdi]\n\t"
        "vmovups ymmword ptr [rsi], ymm0\n\t"
        ".att_syntax prefix\n\t"
        :
        : "D"(name), "S"((*list)->name)
        : "ymm0"
        );

    (*list)->next = old_list;

    return OK;
}
```

Однако, это не привело ни к каким изменениям ни в отчёте `valgrind`'а, ни `perf`'а, ни времени работы. Для анализа ситуации пришлось воспользоваться [godbolt](https://godbolt.org)'ом:

# Скриншоты из godbolt'а
<img src="https://github.com/user-attachments/assets/49fd1f63-1630-420d-b347-c6f67df1948a" width="800">
<img src="https://github.com/user-attachments/assets/e0fec5dc-914a-47f4-a48e-228c3bdc5d83" width="800">
<img src="https://github.com/user-attachments/assets/d1e67ed4-5058-45a5-9e1b-733976e02fff" width="800">
<img src="https://github.com/user-attachments/assets/1775dc07-8847-41d8-9bf2-0195301e929e" width="800">
<img src="https://github.com/user-attachments/assets/7b3df138-1b94-4962-9cc5-dbe06e6329b8" width="800">

Оказалось, что оптимизатор уже делал практически ту же самую вещь, только тратил на это 4 инструкции, а не 2. К тому же тут была замечена неиспользуемая нигде функция (`strlen`), которая благополучно выкидывалась оптимизатором компилятора. По этой же причине не было заметно отличий в результате `valgrind`'а, так как никакого вызова `memcpy` и не было. В таком случае, попробуем что-то сделать с первым вызовом. 

```c++
...
    int len = strlen(name);
    memcpy(smallBuff, name, len);
...
```
В целом, задача этих строк заключается в том, чтобы перенести строку до нулевого символа в буфер `smallBuff`, не совсем эффективно вызывать для этого `strlen` и `memcpy`. В `strlen`'е у нас загружается символ, сравнивается с нулём и после этого увеличивается счётчик, который нам не особо-то и нужен, в то же время `memcpy` у нас проходит работа с этим счётчиком. Была предпринята идея объединить эти функции следующим образом:

```asm
section .text

global strlen_memcpy

strlen_memcpy:

    inline_asm_loop:
    lodsb                   ; загрузка символа из [RSI], увеличение RSI
    test al, al             ; проверка на 0
    jz inline_asm_end
    stosb                   ; загрузка символа в [RDI], увеличение RDI
    jmp inline_asm_loop
    inline_asm_end:

    ret
```

Также, объединив `memcpy` и `strlen`, у нас появилась возможность воспользоваться строковыми инструкциями, что не может не радовать, и к тому же у нас остаётся всего 1 вызов функции вместо 2. Вот измерения:

| Версия            | v1       |  v1_O3     | v2_O3         | v3_O3         | v4_O3         |
|:-:                |:-------: |:----------:|:----------:   |:----------:   |:----------:   |
| Такты * 10^9      |  46,1    |    8,42     |2,63            | 1,95          |   1,89          |  
| Ускорение         |  1,00    |    5,48    |17,7           | 23,8          |24,4          |  
| Отн. ускорение    |  1,00    |    5,48    |3,23           | 1,34          |1,03          |
| Погрешность       |  0,01    |    0,01    |0,06           | 0,04          |0,03          |

# Картинка v4_O3
<img src="https://github.com/user-attachments/assets/556f7c17-bc30-4dfa-88d0-5a1042c1a4ea" width="800">

Исходя из репорта `valgrind`'а можно сделать немало выводов, например, функция `hashTableAdd` теперь заинлайнена в `textParse`, время занятое неким `0x0..01360` сильно увеличилось, как и количество обращений к этому адресу, воспользуеся `perf`'ом для разъяснения ситуации.

# Картинка perf1
<img src="https://github.com/user-attachments/assets/088a73d1-75c1-42b9-ba33-624a1fc556ba" width="800">


# Картинка perf2
<img src="https://github.com/user-attachments/assets/d1079a87-61cc-4571-89fb-6497e9aec622" width="800">

Даже на этих двух отчётах видно, что частоты "скринов" `perf`'а в 100кГц (максимальная частота) не хватает для абсолютно точного получения данных. Итак, `hashTableAdd` и правда пропал с радаров и был заинлайнен, однако, достаточной информации по эффективности `strlen_memcpy` собрать сложно, так как нам не хватает точности `perf`'а, если сравнивать результаты `valgrind`'а с `perf`'ом, то я считаю, `valgrind` ближее к правде - мы избавились от `memcpy` и `strlen` на ~4%, но появился `0x0..01d70` на ~1%, которым, в теории и должен быть наш `strlen_memcpy`. Итого, разница между ними ~3%, что сходится с экспериментальными данными. Это можно подтвердить или опровергнуть используя дизассемблер.

# Вот собственно и скрин из IDA
<img src="https://github.com/user-attachments/assets/b65a1aad-6e2c-4160-8370-b3f4a5abc886" width="800">

Скрин подтверждает, что это и был наш `strlen_memcpy`, также можно подтвердить, что по адресу `0x1360` лежит `meowcmp`.

# Meowcmp IDA
<img src="https://github.com/user-attachments/assets/58e6f411-5b03-4ddd-a1e5-68a6ec5c2724" width="800">

## Результаты и выводы.

Во-первых, хочется сказать, что `perf` и `valgrind` два незаменимых инструмента в профилировании, которые обладают своими преимуществами и недостатками. Например, `valgrind` выдаёт в отчёте точное количество вызовов той или иной функции, однако из его недостатков стоит отметить гигансткое время работы программы во время профилирования и непонятные адреса, возникающие при работе с intrinsic-функциями. С другой стороны, у `perf`'а просто огромный функционал, в том числе: измерение времени работы, просмотр отдельных инструкций, которые занимают большую часть времени работы, а ещё он практически не замедляет работу программы.

### Табличка
| Версия            | v1       |  v1_O3     | v2_O3         | v3_O3         | v4_O3         |
|:-:                |:-------: |:----------:|:----------:   |:----------:   |:----------:   |
| Такты * 10^9      |  46,1    |    8,42     |2,63            | 1,95          |   1,89          |  
| Ускорение         |  1,00    |    5,48    |17,7           | 23,8          |24,4          |  
| Отн. ускорение    |  1,00    |    5,48    |3,23           | 1,34          |1,03          |
| Погрешность       |  0,01    |    0,01    |0,06           | 0,04          |0,03          |

Говоря о проделанных оптимизациях, суммарно программа была ускорена более чем в 24 раза и в ~4 раза относительно `v1_O3` версии, что на самом деле весьма внушительный результат. Несмотря на это, следует отказаться от последней версии `v4_O3` в сторону `v3_O3`, так как количество строк на ассемблере возросло в 2-3 раза, что сильно ухудшило читаемость и переносимость кода, а на производительность это повлияло незначительно.

Был изучен встроенный ассемблер `g++`, проанализирована дальнейшее поведение программы после компилирования с [godbolt](). Для выяснения результатов профилирования с `valgrind`'ом была использована `IDA` и, собственно, написана хэш-таблица с хэш-функцией `crc32`.
        
## Полезные ссылки
- [Гайд по perf'у.](https://habr.com/ru/companies/first/articles/442738/)
- [Инфа по inline-ассемблеру №1.](https://dmalcolm.fedorapeople.org/gcc/2015-08-31/rst-experiment/how-to-use-inline-assembly-language-in-c-code.html#local-reg-vars)
- [Инфа по inline-ассемблеру №2.](https://www.ibiblio.org/gferg/ldp/GCC-Inline-Assembly-HOWTO.html)
